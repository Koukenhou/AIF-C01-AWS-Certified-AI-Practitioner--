# AIF-C01｜2.3.4 生成 AI サービスの**コストに対するトレードオフ**

*AIF-C01 Domain 2, Task 2.3.4 — Cost trade-offs for AWS generative-AI services*

> 目的：在 AWS 上搭建生成式 AI 时，能**系统评估成本 ↔ 体验/可靠性/性能**的取舍，并给出工程化落地做法。
> 术语均给出 **中・日（含读法）・英**，讲解以中文为主。

---

## 0) 关键维度一览（速记表）

| 维度   | 日文（读法）              | English                  | 取舍要点（一句话）                             |
| ---- | ------------------- | ------------------------ | ------------------------------------- |
| 响应性  | 応答性【おうとうせい】         | Responsiveness / Latency | 低延迟更贵（预留/常驻算力）；容忍等待可选异步/批处理省钱。        |
| 可用性  | 可用性【かようせい】          | Availability             | 多 AZ/多 Region 更稳也更贵；容灾级别越高，成本越高。      |
| 冗余   | 冗長性【じょうちょうせい】       | Redundancy               | 主备/双活带来**额外计算+存储+传输**开销。              |
| 性能   | パフォーマンス             | Performance / Throughput | 高并发与 p95 延迟目标越严，越需要**更大/更多**容量或预留吞吐。  |
| 区域   | リージョン展開【りーじょん てんかい】 | Region placement         | 近用戶=低延迟；跨区复制=传输与存储成本上升。               |
| 计费   | トークン課金【とか】          | Token-based pricing      | **输入+输出**都计费；Prompt/RAG 设计决定大头成本。     |
| 预留吞吐 | プロビジョンドスループット       | Provisioned Throughput   | 保证容量与稳定性，但需**按时付费**（闲时也计费）。           |
| 定制模型 | カスタムモデル             | Custom Model             | 微调/继续预训带来**训练+托管**成本；不一定比“RAG+小模型”合算。 |

---

## 1) 応答性／Latency（Bedrock & SageMaker）

**选择面**

* **实时（リアルタイム / Real-time endpoint）**：最低延迟，适合聊天/交互；需要**常驻容量**（昂贵）。
* **异步（非同期 / Asynchronous）**：排队执行，适合长任务（大文档摘要/图像生成）；**便宜**且不阻塞并发。
* **批处理（バッチ / Batch）**：离线大量任务，单价最低；吞吐高但**非交互**。
* **无服务器（サーバレス / Serverless Inference）**：低频/突发负载省钱，但有**冷启动**；最大模型大小/并发有限制。

**降本提速做法**

* **Prompt 压缩**：把规则/角色放**系统提示**并模板化；去冗余上下文。
* **RAG 精准检索**：**别**把整篇文档塞进上下文，只拼接**命中的 chunk**。
* **小模型优先**：相同任务优先试**更小的 FM**；不够再考虑微调。
* **Streaming**：流式返回可显著改善体验（用户感知延迟）。

---

## 2) 可用性・冗長性／Availability & Redundancy

**策略梯度**（从低到高，成本依次上升）

1. **单 AZ**：开发/PoC。
2. **多 AZ**：生产标准（托管服务多已内建）。
3. **跨 Region 备援**：主备；数据复制与跨区带宽**显著增加成本**。
4. **多 Region 双活**：最高可用性；**计算/存储×2**，全链路成本翻倍甚至更多。

**工程要点**

* 按**业务 RTO/RPO** 决定层级；RPO 越小（接近 0），复制与日志开销越大。
* 跨区时注意 **数据主权/合规** 与 **延迟**（可能得就在“用户近区”部署）。

---

## 3) パフォーマンス／Throughput（并发与 p95/p99）

**Bedrock**

* **On-demand**：简单但**抖动**大；高峰可能限流。
* **Provisioned Throughput（预留吞吐）**：保证**并发/吞吐/延迟稳定性**，但**按时计费**（不管有没有用满）。适合稳定高负载或关键业务窗口。

**SageMaker**

* **Endpoint 自动扩缩容**：按并发/CPU/GPU 利用率伸缩（**缩**得慢会浪费钱）。
* **选择实例家族/数量**：为 p95 设定**缓冲**；GPU 昂贵但吞吐高。
* **Serverless Inference**：低频最省；高并发持续流量时**反而不划算**。

---

## 4) リージョン展開／Region Placement

* **就近部署**：降低延迟，提升用户体验；但多个 Region 维护**权限、密钥、配置**更复杂。
* **跨区数据复制**：S3、向量库（OpenSearch/Aurora pgvector）与日志系统都会产生成本。
* **模型可用范围**：并非所有 FM 在每个 Region 都可用；为满足合规/时效，可能被迫使用更贵的选项或中转。

---

## 5) トークン課金／Token-based Pricing（最重要的成本杠杆）

* **基本规则**：**输入 token + 输出 token** 计费；**上下文窗口**越大、提示越冗长，成本越高。
* **RAG 对 token 的影响**：

  * **Chunk 设计**：过大 → 多余 token；过小 → 命中多段，拼接反而**更多 token**。
  * **Top-K**：命中数越多，拼接上下文越长 → 费用 & 延迟上升。
* **减少输出**：控制 **max\_tokens**；把“表格/JSON 模板”提前定义好避免空话。
* **调用次数**：Agent 可能**连环调用**（推理多跳），要在策略里**限制步数**与失败重试次数。

---

## 6) プロビジョンドスループット／Provisioned Throughput（Bedrock）

* **适用场景**：**稳定高负载**、**SLA 严格**、**高峰期**（电商大促、热线高峰）。
* **优点**：容量/延迟可预测、限流概率低。
* **代价**：**保底计费**，闲时也付费；为了冗余通常要**超配**。
* **实践**：只为“核心时段/核心用例”开，其他流量走 **On-demand/Async/Batch/Serverless** 混合。

---

## 7) カスタムモデル／Custom Models（微调/继续预训）

* **收益**：更贴合术语/风格/格式；可**缩短提示**和**减少重试**（间接降本）。
* **成本项**：

  * **训练**（GPU 小时、数据加工/标注、实验反复）；
  * **托管**（专属权重/端点、版本管理）；
  * **评估**（自动+人工）。
* **决策顺序**：**提示工程 → RAG →（必要时）LoRA/QLoRA 微调**；确实不够再考虑“继续预训练”。
* **风险**：数据治理/隐私/版权；上线后**监控漂移**，否则“越训越差”。

---

## 8) “成本 × 体验”的常见配方（看到题干可直接套）

### A. 内部知识问答（中等流量、要有引用）

* **Bedrock + Knowledge Bases**（Top-K=3 左右；Chunk=300–800 token；带引用）
* **Serverless/On-demand** 混合；**输出限定 JSON/要点**
* **Guardrails** 开启 PII/安全分类
* **成本位点**：RAG 命中条数、上下文长度、输出长度

### B. 客服聊天（对外高并发、晚高峰）

* 常态 **On-demand**；高峰期**预留吞吐**
* **小模型 + RAG** 优先；“疑难工单”降级到更强模型
* **Agent 步数上限** + 失败回退策略
* **监控** p95 延迟、拒答率、成本/会话

### C. 批量摘要/翻译（非实时）

* **Batch/Async**；夜间离线
* 长文先**切分**，每段**并行**；**合并摘要**二次调用
* **重试 + 限流**由 **Step Functions** 负责

### D. 低频/突发 Demo 或内测

* **Serverless Inference**（或直接 Bedrock On-demand）
* **Playground** 先找到**最省 token**的提示与参数
* 不做预留、不跨区复制

---

## 9) 题干关键词 → 秒选答案

* **“低延迟/强 SLA/高并发”** → 预留吞吐（Provisioned Throughput）或实时端点；成本↑。
* **“低频/突发/省钱”** → Serverless 或 Async；可接受冷启动/等待。
* **“批量/夜间”** → Batch Transform 或异步。
* **“成本暴涨”** → 缩 Prompt/上下文、降 Top-K、限制 max\_tokens、换小模型+RAG、缓存热问答。
* **“跨区/合规/数据主权”** → 近区部署；但要考虑复制与带宽成本。
* **“稳定性/少限流”** → 预留吞吐；或多 Region 灰度/降级路径（成本更高）。
* **“自定义模型值得吗”** → 先算“训练+托管+评估”总成本 vs “小模型+RAG+好提示”的效果与 TTM。

---

## 10) 术语小词典（中・日・英）

* 响应性：**応答性【おうとうせい】** / Responsiveness
* 可用性：**可用性【かようせい】** / Availability
* 冗余：**冗長性【じょうちょうせい】** / Redundancy
* 性能/吞吐：**パフォーマンス／スループット** / Performance / Throughput
* 区域部署：**リージョン展開** / Region deployment
* 令牌计费：**トークン課金** / Token-based pricing
* 预留吞吐：**プロビジョンドスループット** / Provisioned Throughput
* 定制模型：**カスタムモデル** / Custom model（Fine-tuning / Continued pre-training）
* 异步/批处理：**非同期／バッチ** / Asynchronous / Batch
* 无服务器：**サーバレス** / Serverless Inference

---

### 一句话总括

> **把钱花在刀刃上**：交互就用实时（必要时预留），长任务走异步/批；用**小模型+RAG**和**精简 Prompt**把 token 压下去；只在**高峰或关键场景**启用预留吞吐；跨区与高冗余要**按 RTO/RPO 精算**。
