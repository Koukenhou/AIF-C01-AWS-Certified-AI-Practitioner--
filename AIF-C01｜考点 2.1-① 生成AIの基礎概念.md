# AIF-C01｜2.1-① 生成AIの基礎概念（中・日・英对照，日语含读法）

> 目标：按 **AWS Certified AI Practitioner – Domain 2, Task 2.1** 的第一小点，系统掌握生成式 AI 的基础概念。
> 使用方式：每个术语都给出 **中文解释 → 日文（读法） → English → 关键要点/考试提示**，并补充与 AWS（如 Bedrock、KB/RAG）相关的落地思路。

---

## 0) 总览：这几件“基石”如何协同

* **Token（令牌）** 是模型处理文本的最小单位；
* **Chunking（分块）** 是把长文档切成处理友好的段；
* **Embedding/Vector（嵌入/向量）** 把块或句子变成可检索的数字向量；
* **Prompt Engineering（提示工程）** 让模型“按你想法”输出；
* **Transformer/LLM** 是如今主流的生成式架构与大语言模型；
* **Foundation Model（FM，基盘模型）** 是大规模预训练的可迁移“底座”；
* **Multimodal（多模态）** 把文本、图像、音频等“统一理解/生成”；
* **Diffusion（扩散）** 是图像/视频生成的主流生成范式。
  → 在 AWS 上，常见组合是 **Bedrock +（KB/RAG）+ Guardrails** 来完成企业级生成式 AI。

---

## 1) 令牌（Token）

* **日**：トークン（トークン）
* **EN**：Token
* **中文**：模型处理文本的**基本单位**，可是字、词或“词片”（subword）。计费与**上下文窗口**（一次可处理的长度）都按 token 计算。
* **要点**

  * 常见切分法：BPE、WordPiece 等；
  * **max\_tokens** 限制输出长度；上下文越长、越贵也越慢；
  * 汉字、英文、符号的 token 粒度不同（英文一个词往往被拆成数个 token）。
* **考试提示**：看到“**成本/长度/上下文**”就想到 **token**；要控成本 → 压短输入、抽取要点、用 RAG 定位段落后再传。

---

## 2) 分块（Chunking）

* **日**：チャンク化【チャンクか】
* **EN**：Chunking
* **中文**：把长文档**切成较短的片段**（chunk），便于向量化与检索；通常还会设置 **overlap（重叠）** 以保留上下文连续性。
* **要点**

  * 常见尺寸：200～1,000 字/词片，按语义段、标题层级或句子边界切；
  * **过小**易丢信息，**过大**会让召回不准、成本升高；
  * 与 **Embedding + 向量数据库 + RAG** 搭配使用。
* **考试提示**：题干有“**长文档、知识库、检索增强**”→ 想到 **Chunk + Embedding + RAG**。

---

## 3) 嵌入/向量（Embedding / Vector）

* **日**：埋め込み表現【うめこみ ひょうげん】／エンベディング；ベクトル
* **EN**：Embedding / Vector
* **中文**：把文本/图像等映射到**高维向量空间**的表示方式；语义相近 → 向量距离更近（常用**余弦相似度**）。
* **要点**

  * 用于 **语义检索、聚类、去重、推荐、RAG 检索阶段**；
  * 维度（如 384/768/1024…）影响存储与召回性能；
  * **嵌入 ≠ token**：嵌入是语义向量，token 是文本最小单元。
* **考试提示**：看到“**相似度/语义搜索/向量数据库**”→ 选 **Embedding/Vector**；在 AWS 可用 **Bedrock Knowledge Bases** 托管向量检索。

---

## 4) 提示工程（Prompt Engineering）

* **日**：プロンプトエンジニアリング
* **EN**：Prompt Engineering
* **中文**：通过**结构化的提示**（任务说明、示例、约束、格式）与**推理参数**（temperature、top\_p、max\_tokens 等）来引导输出。
* **要点（实用清单）**

  * 明确**角色/目标/受众/风格**；
  * 用**分隔符**组织上下文（如：`<<<context>>>`）；
  * **把真正问题放在最后**；指定**输出格式**（JSON/表格）；
  * Few-shot（少样本示例）、思路分步（要求“逐步推理/先列要点后生成”）\*；
  * 参数：**temperature↓ → 更稳定；↑ → 更创意**。
* **考试提示**：题干“**答案不稳定/发散**”→ 降 temperature、收窄 top\_p、提示更结构化；“**输出需可解析**”→ 让模型按 JSON 返回。
  \*（考试只需概念，不要求展示推理细节。）

---

## 5) Transformer ベースの LLM

* **日**：トランスフォーマー ベースの 大規模言語モデル【だいきぼ げんごモデル】
* **EN**：Transformer-based LLM
* **中文**：以 **自注意力（Self-Attention）** 为核心的模型家族；LLM 用大量文本**事前训练**后具备强大的理解与生成能力。
* **要点**

  * 架构：Encoder/Decoder（或 Decoder-only）；
  * 能够**长距离建模**，训练易并行扩展；
  * 局限：**幻觉**、上下文窗口有限、对时效/私域知识不了解（需 RAG/微调）。
* **考试提示**：见“**注意力/上下文窗口/自回归生成**”→ Transformer/LLM；**让 LLM 了解最新/私有知识** → RAG。

---

## 6) 基盘模型（Foundation Model, FM）

* **日**：基盤モデル【きばんモデル】／ファウンデーションモデル
* **EN**：Foundation Model (FM)
* **中文**：在海量多样数据上预训练、可迁移到多任务的大模型“底座”。可直接**零样本/少样本**用，也可**微调**或**持续预训练**做定制。
* **要点**

  * 适配方式：**提示工程 → RAG → 微调（Fine-tune）** 逐步加深；
  * 优势：复用性强、交付快；
  * 风险：数据治理、合规、成本与延迟。
* **AWS 关联**：**Amazon Bedrock** 提供多家 FM 的统一 API，另有 **Guardrails（安全）**、**Knowledge Bases（RAG）**、**Agents**（工具编排）。

---

## 7) マルチモーダルモデル（多模态模型）

* **日**：マルチモーダルモデル
* **EN**：Multimodal Model
* **中文**：可同时处理/关联**文本、图像、音频、视频、表格**等多种模态的模型；常见任务有**看图问答、图文互生、语音对话**。
* **要点**

  * 不同模态会被编码成**统一的“模态 token/向量”**；
  * 用例：**图片理解+文字回答**、**音频转写+摘要**、**图像生成/编辑**。
* **考试提示**：题干出现“**图+文/音+文/表+文**”→ 选 **Multimodal**；在 AWS 可通过 **Bedrock** 选择具备多模态能力的 FM。

---

## 8) 拡散モデル（扩散模型）

* **日**：拡散モデル【かくさんモデル】
* **EN**：Diffusion Model
* **中文**：**逐步去噪**的生成范式：先把图像映射到噪声分布（前向扩散），再学会**从噪声一步步还原**（反向扩散）以**生成新图像/视频**。
* **要点**

  * 参数：步数、调度器、指导系数（guidance scale）；
  * 优势：生成质量高、模式覆盖广；
  * 成本：推理较慢（需多步采样），可用加速采样/蒸馏/裁剪。
* **考试提示**：题干有“**图像生成/去噪/一步步采样**”→ 选 **Diffusion**；与 \*\*LLM（文本）\*\*区分开来。

---

## 9) 概念关系图（文字版）

```
文档 → 分块(Chunk) → 嵌入(Embedding/Vector) → 向量检索
                                     ↓（RAG补充上下文）
                          Prompt(提示工程) + Inference参数
                                     ↓
                   Transformer/LLM（或 多模态/扩散模型）
                                     ↓
                      生成/回答/图像/代码/语音 等结果
```

> 企业落地常见路径：**KB/RAG 保证“知道”→ Guardrails 保证“合规”→ Prompt/参数保“可控”**。

---

## 10) 高频混淆与速记

* **Token vs Embedding**：Token 是“文本单位”，Embedding 是“语义向量”。
* **Chunk vs Token**：Chunk 是“文档切片”（段落级），Token 是“模型单位”（字/词片）。
* **LLM vs FM**：LLM 多指**语言**模型；FM 是更宽泛的“**预训练底座**”（可含语言、图像、多模态）。
* **LLM vs Diffusion**：前者主要**文本生成/理解**，后者主要**图像/视频生成**。
* **提示不稳** → 降 **temperature**、限定 **top\_p**、加格式/示例；
* **长文档失效** → 做 **Chunking + Embedding + RAG**；
* **要最新/私域知识** → RAG，而非单靠“更大模型”。

---

## 11) 术语小词典（中・日・英 Quick Map）

* 令牌：トークン / Token
* 分块：チャンク化 / Chunking
* 嵌入：埋め込み表現／エンベディング / Embedding
* 向量：ベクトル / Vector
* 提示工程：プロンプトエンジニアリング / Prompt Engineering
* 自注意力：自己注意【じこちゅうい】/ Self-Attention
* 大语言模型：大規模言語モデル / Large Language Model
* 基盘模型：基盤モデル / Foundation Model
* 多模态：マルチモーダル / Multimodal
* 扩散模型：拡散モデル / Diffusion Model
* 检索增强生成：検索拡張生成 / Retrieval-Augmented Generation (RAG)
* 守护栏：ガードレール / Guardrails

---

### 一句话总括

> **生成式 AI 的底层语义三件套**：**Token → Chunk → Embedding/Vector**；
> **生成引擎**：**Transformer-based LLM / Multimodal / Diffusion**；
> **可控与落地**：**Prompt Engineering + Inference 参数 + RAG + Guardrails**。
****