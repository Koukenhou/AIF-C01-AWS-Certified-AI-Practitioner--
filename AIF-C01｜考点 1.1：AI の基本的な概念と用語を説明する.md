# AIF-C01｜考点 1.1：AI の基本的な概念と用語を説明する（中・日・英对照版）

> 依据官方考试指南 *AWS Certified AI Practitioner Exam Guide* 的 **目标 1.1** 要求整理。内容覆盖：基础术语、AI/ML/深度学习的异同、推理方式、数据类型、学习范式（监督/非监督/强化）。
> 记忆建议：先背“表格 + 口诀”，再看后面的对比与场景判断。

---

## 0) 一页速览（会背就能拿分）

* **AI / ML / 深度学习**：AI 最大；ML 是 AI 的子集；**深度学习**是 ML 的子集（多层神经网络）。
* **推理类型**：**バッチ（批处理）**=不急、量大；**リアルタイム**=低延迟；**非同期**=长任务；**サーバレス**=低频按需。
* **数据类型**：**有标签 vs 无标签**；**表格/时序**（结构化） vs **图像/文本**（非结构化）。
* **学习方式**：**监督**=有答案；**非监督**=无答案找结构；**强化**=试错+奖励。
* **口诀**：**“先分清数据与目标 → 再选学习方式 → 再定模型与推理形态。”**

---

## 1) 基本术语对照表（中・日【读音】・英 + 中文简释 + 考点提示）

| 中文术语       | 日语（读音）                        | English                      | 中文简释               | 考点提示/易混淆                             |
| ---------- | ----------------------------- | ---------------------------- | ------------------ | ------------------------------------ |
| 人工智能       | 人工知能【じんこうちのう】                 | Artificial Intelligence (AI) | 让机器执行需要“智能”的任务的总称  | **AI ⊃ ML ⊃ 深度学习** 的层级               |
| 机器学习       | 機械学習【きかいがくしゅう】                | Machine Learning (ML)        | 从数据中学习规律           | 结构化任务常用；强调**特征工程**                   |
| 深度学习       | 深層学習【しんそうがくしゅう】               | Deep Learning (DL)           | 多层神经网络自动学特征        | 适合**图像/语音/文本**等非结构化                  |
| 神经网络       | ニューラルネットワーク                   | Neural Network               | 由“人工神经元”连接的模型家族    | DL 的方法载体                             |
| 计算机视觉      | コンピュータビジョン                    | Computer Vision              | 让机器“看懂”图像/视频       | CNN/YOLO/U-Net 等                     |
| 自然语言处理     | 自然言語処理【しぜんげんごしょり】             | NLP                          | 让机器“读懂/写出”人类语言     | Comprehend/LLM                       |
| 模型         | モデル                           | Model                        | 训练得到的可推理的参数化函数     | 训练=fit；推理=infer                      |
| 算法         | アルゴリズム                        | Algorithm                    | 解决问题的步骤/方法         | 决策树/SVM/CNN/Transformer              |
| 训练         | トレーニング                        | Training                     | 用数据更新参数以拟合任务       | 输出是**模型文件/权重**                       |
| 推理         | 推論【すいろん】                      | Inference                    | 用训练好的模型做预测         | **Batch/Real-time/Async/Serverless** |
| 拟合/过拟合/欠拟合 | フィット/過学習【かがくしゅう】/欠学習【けつがくしゅう】 | Fit/Overfitting/Underfitting | 拟合=学会规律；过/欠拟合=泛化差  | 看验证集、正则化、早停                          |
| 偏差/公平      | バイアス/公平性【こうへいせい】              | Bias/Fairness                | 统计偏差或数据/算法偏见；公平性治理 | 负责任 AI（Responsible AI）               |
| 大语言模型      | 大規模言語モデル【だいきぼげんごモデル】          | LLM                          | 生成/理解文本的超大模型       | Token/上下文/温度/Top-p                   |
| 基础模型       | 基盤モデル【きばんモデル】                 | Foundation Model (FM)        | 大规模预训练、可迁移到多任务     | Bedrock 托管多家 FM                      |
| 检索增强生成     | 検索拡張生成【けんさくかくちょうせいせい】         | RAG                          | “先检索再生成”，带引用更可信    | 降低幻觉；与知识库联用                          |
| 知识库        | ナレッジベース/知識ベース                 | Knowledge Base (KB)          | 托管/自建的文档与向量索引      | Bedrock Knowledge Bases              |
| 嵌入         | エンベディング/埋め込み【うめこみ】            | Embedding                    | 把文本/对象映射为向量        | 向量检索/相似度                             |
| 令牌/上下文     | トークン/コンテキストウィンドウ              | Token/Context Window         | 计费与上下文单位/一次可处理上限   | 控成本=短上下文+限输出                         |
| 守护栏        | ガードレール                        | Guardrails                   | 输入/输出的安全与内容策略      | 合规、PII 过滤、格式约束                       |
| 监督学习       | 教師あり学習【きょうしありがくしゅう】           | Supervised Learning          | 有标签学习输入→输出         | 分类/回归                                |
| 非监督学习      | 教師なし学習【きょうしなしがくしゅう】           | Unsupervised Learning        | 无标签发现结构            | 聚类/PCA/自编码器                          |
| 强化学习       | 強化学習【きょうかがくしゅう】               | Reinforcement Learning       | 试错+奖励学策略           | Agent/Reward/Environment             |

> **记忆法**：AI 大圈；圈内是 ML；圈中之圈是 DL。**“结构化→ML；非结构化→DL；要引用→RAG；只生成→LLM。”**

---

## 2) AI・ML・深度学习：相似点与相异点

**相似点**：都用算法+数据解决“智能任务”，强调评估与泛化。
**不同点**（答题要点）：

* **范围**：AI（最大） ⊃ ML ⊃ **深度学习**
* **特征获取**：传统 ML 依赖**人工特征工程**；DL **自动学特征**
* **数据/算力**：DL 更吃数据与 GPU；ML 对结构化中小数据更友好
* **适用**：表格/时序→ML 优先；图像/语音/文本→DL 优先

**口诀**：**“任务看数据：表格去 ML，图像找 DL；要证据就 RAG。”**

---

## 3) 推理（Inference）类型与适用场景

| 推理方式 | 日文       | 说明          | 典型场景         | 关键词       |
| ---- | -------- | ----------- | ------------ | --------- |
| 批处理（Batch）  | バッチ推論    | 一次性离线处理大量样本 | 夜间批量跑巡检照片    | 不急、量大、成本低 |
| 实时（Real-time）   | リアルタイム推論 | 低延迟在线接口     | App 上传即出结果   | 毫秒级响应     |
| 异步（Asynchronous）   | 非同期推論    | 请求/结果分离，长任务 | 大图/视频，稍后回写结果 | 长耗时、解耦    |
| 无服务器（Serverless） | サーバレス推論  | 按需调度，不预留实例  | 低频调用/PoC     | 冷启动、低成本   |

**一行记忆**：**不急用批；要即刻用实时；任务长用异步；低频用无服务器。**

---

## 4) 数据类型（模型能吃什么样的数据）

| 维度   | 日文      | 说明    | 例子            | 常见方法           |
| ---- | ------- | ----- | ------------- | -------------- |
| 有标签(Labeled)  | ラベル付き   | 有正确答案 | 照片→“裂缝/坑洼/良好” | 监督学习（分类/回归）    |
| 无标签(Unlabeled)  | ラベルなし   | 没有答案  | 20万无标签照片      | 聚类/自监督/半监督     |
| 表格(Tabular)   | 表形式データ  | 行列结构化 | 传感器、SQL、Excel | XGBoost/树模型    |
| 时间序列(Time-series) | 時系列データ  | 有时间顺序 | 天气/流量/健康度曲线   | RNN/TFT/ARIMA  |
| 图像(Image)   | 画像データ   | 像素矩阵  | 路面照片/卫星图      | CNN/YOLO/U-Net |
| 文本(Text)   | テキストデータ | 自然语言  | 投诉、报告、FAQ     | NLP/LLM        |
| 结构化(Structured)  | 構造化データ  | 架构固定  | 表格/关系库        | 传统 ML          |
| 非结构化(Unstructured) | 非構造化データ | 无固定架构 | 图像/音频/视频/自由文本 | 深度学习/NLP/CV    |

**判断法**：先看输入形态；**结构化→ML；非结构化→DL；要“带引用/最新知识”→RAG/KB**。

---

## 5) 学习方式（监督/非监督/强化）

| 学习方式  | 日文     | 要点             | 典型题干                   |
| ----- | ------ | -------------- | ---------------------- |
| 监督学习(Supervised Learning)  | 教師あり学習 | 有标签，学映射（分类/回归） | “有答案/ラベル付き/预测”         |
| 非监督学习(Unsupervised Learning) | 教師なし学習 | 无标签，找结构（聚类/降维） | “クラスタリング/特征抽取”         |
| 强化学习(Reinforcement Learning)  | 強化学習   | 试错+奖励，学策略      | “報酬/Agent/Environment” |

**一口气**：**有标签→监督；无标签→非监督；靠奖励→强化。**

---

## 6) 高频易混淆 & 秒选提示

* **Kendra vs RAG/KB**：只要**搜索/FAQ**→ Kendra；**带引用生成**→ RAG/KB。
* **Comprehend vs LLM**：**抽取/情感/实体**→ Comprehend；**摘要/改写/对话**→ LLM。
* **Bedrock vs SageMaker**：**托管多家 FM 直接调用**→ Bedrock；**训练/微调/部署/MLOps**→ SageMaker。
* **Overfitting（過学習）**：训练好、考试差→加正则/早停/更多数据。
* **Token/Context**：**成本=输入+输出 Token**；控成本→**短上下文+限输出**。
* **Guardrails**：合规 & 安全边界（PII/话题/格式）；与 **低温度+结构化输出** 搭配。

---

## 7) 速记口诀（背下就会做题）

* **层级**：**AI 大圈，ML 次圈，DL 小圈**。
* **选型**：**表格时序→ML；图像文本→DL；要引用→RAG；只生成→LLM**。
* **推理**：**批不急、实实时、异步长、无服低频省**。
* **学习**：**有标签监督；无标签非监督；奖励强化**。
* **治理**：**合规>可靠>成本>体验**；**Guardrails+加密+审计**。

---

> 以上内容与官方 *AIF-C01 Exam Guide* 的 **Domain 1, Task Statement 1.1** 对齐，并结合备考常见混淆点做了展开。你可以把第 1 节“术语表”单独复印成记忆卡，按**中文→日文读法→英文→考点提示**的顺序每天快背 5 分钟。需要我把这份表做成 Anki/Excel 模板吗？
